{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8688425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ICS 438 Final Project:\n",
    "# Jerome Gallego, Taylor Wong, Ujjwal Gautam\n",
    "# December 13, 2022\n",
    "#\n",
    "# For this project we have decided to use a dataset made from yelp reviews. \n",
    "# Using the operation known as Sentiment Analysis, we can provide a detailed investigation on whether or not the star ratings\n",
    "# -can reflect how positive, negative, or neutral each review is.\n",
    "\n",
    "# In the yelp dataset, we will only be analyzing the star ratings and the reviews itself. Everything else can be considered irrelevant\n",
    "\n",
    "#For this notebook please install these packages to ensure that the file is running correctly\n",
    "%pip install -U gensim\n",
    "%pip install nltk\n",
    "\n",
    "\n",
    "\n",
    "# Import whatever libraries you would want to use\n",
    "# Clean up cells to put all imports to the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151c0f68-a2c9-48f9-b9fc-d1078eb8dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import gensim\n",
    "# from gensim.parsing.preprocessing import remove_stopwords\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f3db4c-fdc6-453a-b103-99df5b07e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before we can do any kind of analysis we will need to load the dataset.\n",
    "# As instructed, we understand that loading a file into ram can seem inefficient,\n",
    "# to overcome this obstacle we have decided to process the data using the batching method that we have learned from Mahdi.\n",
    "\n",
    "## Process yelp.csv with chunk size of 50 and append it to the dataframe\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "with open('./data/yelp.csv', \"r+\") as csv_file:\n",
    "    tp = pd.read_csv(csv_file, iterator=True, chunksize=50)\n",
    "    df = pd.concat(tp, ignore_index=True) \n",
    "# df.shape\n",
    "# df.head()\n",
    "# df['type'].describe\n",
    "# df.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a62b7a-cef7-46e1-852b-b4fcd8d3c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id', 'cool', 'useful', 'funny']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns.values.tolist()\n",
    "print(columns)\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36cbf547-40c0-4bb1-858a-70acfe705243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text\n",
       "0         5  My wife took me here on my birthday for breakf...\n",
       "1         5  I have no idea why some people give bad review...\n",
       "2         4  love the gyro plate. Rice is so good and I als...\n",
       "3         5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4         5  General Manager Scott Petello is a good egg!!!...\n",
       "...     ...                                                ...\n",
       "9995      3  First visit...Had lunch here today - used my G...\n",
       "9996      4  Should be called house of deliciousness!\\n\\nI ...\n",
       "9997      4  I recently visited Olive and Ivy for business ...\n",
       "9998      2  My nephew just moved to Scottsdale recently so...\n",
       "9999      5  4-5 locations.. all 4.5 star average.. I think...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To ensure we have removed all the irrelevant columns, we used the function drop() which will tell\n",
    "## the dataframe to only include the stars and the text review. \n",
    "df.drop(labels=[\"business_id\", \"date\", \"type\", \"review_id\", \"user_id\", \"cool\", \"useful\", \"funny\"], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db326b83-c536-4e1b-95fd-64fe396c5d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Cleaning the data\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import string\n",
    "def clean_data(data):\n",
    "    x = data.lower()\n",
    "    x = x.replace('\\n','')\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation)) \n",
    "    x = x.translate(table)\n",
    "    x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2403df8-b33c-43fb-ad15-019d774dde6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>wife took birthday breakfast excellent  weathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>idea people give bad reviews place goes show p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love gyro plate rice good also dig candy selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>rosie dakota love chaparral dog park convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>general manager scott petello good egg go deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3</td>\n",
       "      <td>first visithad lunch today  used groupon  orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>4</td>\n",
       "      <td>called house deliciousnessi could go item item...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "      <td>recently visited olive ivy business last week ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>nephew moved scottsdale recently bunch friends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5</td>\n",
       "      <td>45 locations 45 star average think arizona rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text\n",
       "0         5  wife took birthday breakfast excellent  weathe...\n",
       "1         5  idea people give bad reviews place goes show p...\n",
       "2         4  love gyro plate rice good also dig candy selec...\n",
       "3         5  rosie dakota love chaparral dog park convenien...\n",
       "4         5  general manager scott petello good egg go deta...\n",
       "...     ...                                                ...\n",
       "9995      3  first visithad lunch today  used groupon  orde...\n",
       "9996      4  called house deliciousnessi could go item item...\n",
       "9997      4  recently visited olive ivy business last week ...\n",
       "9998      2  nephew moved scottsdale recently bunch friends...\n",
       "9999      5  45 locations 45 star average think arizona rea...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##apply clean_data function to the df[\"text\"] column to remove punctuations, new lines, and stop words\n",
    "df[\"text\"] = df[\"text\"].apply(clean_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3a00e6-94e7-494d-b839-5f27544b5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see there are 10000 entries in the file. By using Pandas Dataframe, it is good to know that we will not be able to\n",
    "# -completely store all the data in RAM. With that being said to make it seem more realistic, we will cut down the dataframe\n",
    "# -to have only 1000 randomly selected reviews. \n",
    "# Again, in some situations that can be too much for a machine to handle. To prevent any crashes or errors, we will be\n",
    "# -batching the reviews in a set of 50 at a time.\n",
    "# Thanks to the help of Assignment 2, we understand how to batch a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6818bb0-a4cf-452a-bf12-277f10be05c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>4</td>\n",
       "      <td>simply put grind provided one top five burgers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>5</td>\n",
       "      <td>disgruntled reviews read sapporo  things say1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2</td>\n",
       "      <td>uhhhthese supposed carne fries asu boys think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9217</th>\n",
       "      <td>5</td>\n",
       "      <td>eat 3 times week antipasto salad bread addicti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>3</td>\n",
       "      <td>love eat however hit miss sometimes get good s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>3</td>\n",
       "      <td>great see total wine closer live  large select...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>3</td>\n",
       "      <td>want really filling delicious pleasemakemyhead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>5</td>\n",
       "      <td>going nails 101 long time love manicure done m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>4</td>\n",
       "      <td>hubby go almost ever friday happy hour love ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>4</td>\n",
       "      <td>im sushi expert stretch suffice say rolls well...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text\n",
       "6967      4  simply put grind provided one top five burgers...\n",
       "3152      5  disgruntled reviews read sapporo  things say1 ...\n",
       "834       2  uhhhthese supposed carne fries asu boys think ...\n",
       "9217      5  eat 3 times week antipasto salad bread addicti...\n",
       "6094      3  love eat however hit miss sometimes get good s...\n",
       "...     ...                                                ...\n",
       "4809      3  great see total wine closer live  large select...\n",
       "5260      3  want really filling delicious pleasemakemyhead...\n",
       "2439      5  going nails 101 long time love manicure done m...\n",
       "6673      4  hubby go almost ever friday happy hour love ch...\n",
       "2077      4  im sushi expert stretch suffice say rolls well...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using sample() will randomly select 1000 reviews for analysis\n",
    "df = df.sample(n=1000)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22fe0c54-cc4d-4f02-97f1-61b91f8dc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we have cleaned the data to remove any sort of stop words and characters, we can start to implement the Sentiment Analysis.\n",
    "# The main goal for this is produce a score from 0 to 1 whether it is categorized as Positive, Negative, or Neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47714df8-c1bd-4e93-993b-c048864f9f55",
   "metadata": {},
   "source": [
    "### Vader lexicon\n",
    "Vader lexicon is a rule-based sentiment analysis tool specifically made for social media sentiment. \n",
    "\n",
    "### Why we chose vader lexicon\n",
    "We decided to go with vader lexicon since the way vader lexicon was designed is meant for review analysis. On their GitHub page, examples of the training data used include 'The service here is extremely good', and 'The service here is go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9d2282c-cdd7-4f2e-9b89-c93b0fd00e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "/tmp/ipykernel_1413/3360358221.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for index, row in df['text'].iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>4</td>\n",
       "      <td>simply put grind provided one top five burgers...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.8854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>5</td>\n",
       "      <td>disgruntled reviews read sapporo  things say1 ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.8625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2</td>\n",
       "      <td>uhhhthese supposed carne fries asu boys think ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9217</th>\n",
       "      <td>5</td>\n",
       "      <td>eat 3 times week antipasto salad bread addicti...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>3</td>\n",
       "      <td>love eat however hit miss sometimes get good s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>3</td>\n",
       "      <td>great see total wine closer live  large select...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.7845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>3</td>\n",
       "      <td>want really filling delicious pleasemakemyhead...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>5</td>\n",
       "      <td>going nails 101 long time love manicure done m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>4</td>\n",
       "      <td>hubby go almost ever friday happy hour love ch...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.9777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>4</td>\n",
       "      <td>im sushi expert stretch suffice say rolls well...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.9862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars                                               text Sentiment  \\\n",
       "6967      4  simply put grind provided one top five burgers...  positive   \n",
       "3152      5  disgruntled reviews read sapporo  things say1 ...  positive   \n",
       "834       2  uhhhthese supposed carne fries asu boys think ...  negative   \n",
       "9217      5  eat 3 times week antipasto salad bread addicti...   neutral   \n",
       "6094      3  love eat however hit miss sometimes get good s...  positive   \n",
       "...     ...                                                ...       ...   \n",
       "4809      3  great see total wine closer live  large select...  positive   \n",
       "5260      3  want really filling delicious pleasemakemyhead...  positive   \n",
       "2439      5  going nails 101 long time love manicure done m...  positive   \n",
       "6673      4  hubby go almost ever friday happy hour love ch...  positive   \n",
       "2077      4  im sushi expert stretch suffice say rolls well...  positive   \n",
       "\n",
       "        neg    neu    pos  compound  \n",
       "6967  0.071  0.747  0.183    0.8854  \n",
       "3152  0.157  0.605  0.237    0.8625  \n",
       "834   0.176  0.649  0.175   -0.2732  \n",
       "9217  0.000  1.000  0.000    0.0000  \n",
       "6094  0.098  0.556  0.346    0.9517  \n",
       "...     ...    ...    ...       ...  \n",
       "4809  0.000  0.711  0.289    0.7845  \n",
       "5260  0.102  0.603  0.295    0.8230  \n",
       "2439  0.000  0.641  0.359    0.8555  \n",
       "6673  0.038  0.549  0.414    0.9777  \n",
       "2077  0.030  0.558  0.413    0.9862  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon') #WE NEED TO EXPLAIN WHAT THIS IS\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #WE NEED TO EXPLAIN WHAT THIS IS ALSO\n",
    "\n",
    "for index, row in df['text'].iteritems():\n",
    "    result = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    # if index%50 == 0:\n",
    "    if result['neg'] > result['pos']:\n",
    "        df.loc[index, \"Sentiment\"] = \"negative\"\n",
    "    elif result['pos'] > result['neg']:\n",
    "        df.loc[index, \"Sentiment\"] = \"positive\"\n",
    "    else:\n",
    "        df.loc[index, \"Sentiment\"] = \"neutral\"\n",
    "        \n",
    "    df.loc[index, 'neg'] = result['neg']\n",
    "    df.loc[index, 'neu'] = result['neu']\n",
    "    df.loc[index, 'pos'] = result['pos']\n",
    "    df.loc[index, 'compound'] = result['compound']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b65d356-9f90-4672-9e21-c0c684cdb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_stars = df[df['stars'] == 1]\n",
    "# one_stars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560299f-9403-4fcc-a284-fd23ac92452f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
